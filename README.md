# AI-Sisters-test_technique

# ‚öñÔ∏è RAG Legal Chatbot

Application de chatbot intelligent bas√©e sur RAG (Retrieval-Augmented Generation) pour le cabinet d'avocats **Emilia Parenti**, sp√©cialis√© en droit des affaires √† Paris.

---

## üìã Table des Mati√®res

- [Vue d'ensemble](#-vue-densemble)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Architecture](#-architecture)
- [Pr√©requis](#-pr√©requis)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Utilisation](#-utilisation)
- [Structure du Projet](#-structure-du-projet)
- [Technologies](#-technologies)
- [D√©pannage](#-d√©pannage)
- [Licence](#-licence)

---

## üéØ Vue d'ensemble

Ce chatbot permet aux avocats du cabinet de :
- üìÑ **Uploader** des documents juridiques (contrats, notes, proc√©dures)
- üîç **Rechercher** des informations sp√©cifiques dans une base documentaire
- üí¨ **Poser des questions** en langage naturel
- ‚úÖ **Obtenir des r√©ponses pr√©cises** avec citation des sources

Le syst√®me utilise la technique **RAG (Retrieval-Augmented Generation)** pour combiner :
1. **Recherche s√©mantique** dans une base vectorielle (FAISS ou ChromaDB)
2. **G√©n√©ration de r√©ponses** via GPT-4 (OpenAI)

---

## ‚ú® Fonctionnalit√©s

### üìÑ Gestion des Documents

- ‚úÖ Upload de fichiers multiples (`.txt`, `.csv`, `.html`)
- ‚úÖ Validation automatique (taille, format)
- ‚úÖ Traitement et chunking intelligent
- ‚úÖ Vectorisation avec embeddings OpenAI
- ‚úÖ Suppression s√©lective de documents
- ‚úÖ Statistiques en temps r√©el

### üí¨ Interface de Chat

- ‚úÖ Questions en langage naturel
- ‚úÖ R√©ponses contextualis√©es avec sources
- ‚úÖ Historique de conversation (contexte multi-tours)
- ‚úÖ Export de conversation
- ‚úÖ Validation des questions
- ‚úÖ Interface moderne et responsive

### üîß Configuration Avanc√©e

- ‚úÖ Choix du vector store (FAISS ou ChromaDB)
- ‚úÖ Configuration du mod√®le LLM
- ‚úÖ Param√©trage du chunking
- ‚úÖ Logging d√©taill√© avec rotation
- ‚úÖ Variables d'environnement (.env)

---

## üèóÔ∏è Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Interface Streamlit                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   üí¨ Chat            ‚îÇ  ‚îÇ  üìÑ Gestion Documents      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                      ‚îÇ  ‚îÇ                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Questions         ‚îÇ  ‚îÇ  - Upload                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Historique        ‚îÇ  ‚îÇ  - Suppression             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Sources           ‚îÇ  ‚îÇ  - Statistiques            ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Couche M√©tier                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    LLMHandler                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - G√©n√©ration de r√©ponses                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Gestion du contexte                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Validation des questions                          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                              ‚îÇ                               ‚îÇ
‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ        ‚ñº                                             ‚ñº        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  DocumentProcessor   ‚îÇ        ‚îÇ  VectorStoreManager  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                      ‚îÇ        ‚îÇ                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Extraction texte  ‚îÇ        ‚îÇ  - Recherche         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Chunking          ‚îÇ        ‚îÇ  - Ajout/Suppression ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Validation        ‚îÇ        ‚îÇ  - Statistiques      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Couche Donn√©es                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Fichiers        ‚îÇ  ‚îÇ  Base Vectorielle ‚îÇ  ‚îÇ  OpenAI   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Upload√©s        ‚îÇ  ‚îÇ  (FAISS/Chroma)  ‚îÇ  ‚îÇ  API      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  /data/uploads/  ‚îÇ  ‚îÇ  /data/vector/   ‚îÇ  ‚îÇ  GPT-4    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flux de Traitement d'une Question
```mermaid
graph TD
    A[User pose question] --> B[LLMHandler.generate_response]
    B --> C[VectorStoreManager.similarity_search]
    C --> D[R√©cup√©ration TOP_K chunks]
    D --> E[Construction du contexte]
    E --> F[Construction du prompt syst√®me + contexte]
    F --> G[Appel API OpenAI GPT-4]
    G --> H[Extraction des sources]
    H --> I[Retour r√©ponse + sources]
```

---

## üì¶ Pr√©requis

### Syst√®mes d'Exploitation

- ‚úÖ Windows 10/11
- ‚úÖ macOS 12+
- ‚úÖ Linux (Ubuntu 20.04+)

### Logiciels Requis

- **Python 3.11+** ([T√©l√©charger](https://www.python.org/downloads/))
- **Git** (optionnel, pour cloner le repo)

### Cl√© API

- **OpenAI API Key** ([Obtenir une cl√©](https://platform.openai.com/api-keys))

### Windows Uniquement (si ChromaDB)

Si vous souhaitez utiliser **ChromaDB** au lieu de FAISS :

- **Microsoft Visual C++ Build Tools** ([T√©l√©charger](https://visualstudio.microsoft.com/visual-cpp-build-tools/))
  - Cocher "Desktop development with C++" lors de l'installation

‚ö†Ô∏è **Note** : FAISS est recommand√© sur Windows (pas besoin de Build Tools)

---

## üöÄ Installation

### 1Ô∏è‚É£ Cloner le Projet
```bash
# Via Git
git clone https://github.com/DonaldFeuz/AI-Sisters-test_technique.git
cd AI-Sisters-test_technique

# Ou t√©l√©charger le ZIP et extraire
```

### 2Ô∏è‚É£ Cr√©er un Environnement Virtuel

#### Windows (PowerShell)
```powershell
python -m venv venv
.\venv\Scripts\Activate
```

#### macOS/Linux
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3Ô∏è‚É£ Installer les D√©pendances
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

## ‚öôÔ∏è Configuration

### 1Ô∏è‚É£ Cr√©er le Fichier `.env`

Copier `.env.example` en `.env` (ou cr√©er un nouveau fichier) :
```bash
# Windows PowerShell
Copy-Item .env.example .env

# macOS/Linux
cp .env.example .env
```

### 2Ô∏è‚É£ Configurer les Variables

√âditer `.env` avec vos param√®tres :
```env
# =============================================================================
# CONFIGURATION - RAG Legal Chatbot
# =============================================================================

# -----------------------------------------------------------------------------
# OpenAI API
# -----------------------------------------------------------------------------
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------
LLM_MODEL=gpt-4o                    # Mod√®le: gpt-4o, gpt-4-turbo-preview, gpt-3.5-turbo
LLM_TEMPERATURE=0.0                 # Temp√©rature (0.0 = d√©terministe, 1.0 = cr√©atif)
MAX_TOKENS=1000                     # Nombre max de tokens dans la r√©ponse

# -----------------------------------------------------------------------------
# Embeddings Configuration
# -----------------------------------------------------------------------------
EMBEDDING_MODEL=text-embedding-3-small

# -----------------------------------------------------------------------------
# Vector Store Configuration
# -----------------------------------------------------------------------------
VECTOR_STORE_TYPE=faiss             # Type: faiss ou chroma (FAISS recommand√© pour Windows)
TOP_K_RESULTS=5                     # Nombre de chunks r√©cup√©r√©s par recherche

# -----------------------------------------------------------------------------
# Document Processing
# -----------------------------------------------------------------------------
CHUNK_SIZE=1000                     # Taille des chunks (en caract√®res)
CHUNK_OVERLAP=200                   # Chevauchement entre chunks
MAX_UPLOAD_SIZE_MB=10               # Taille max par fichier upload√© (MB)

# -----------------------------------------------------------------------------
# Application
# -----------------------------------------------------------------------------
APP_TITLE=RAG Legal Chatbot
APP_ICON=‚öñÔ∏è
```

### 3Ô∏è‚É£ Variables Importantes

| Variable | Description | Valeurs Possibles |
|----------|-------------|-------------------|
| `OPENAI_API_KEY` | Cl√© API OpenAI | `sk-proj-...` |
| `LLM_MODEL` | Mod√®le GPT √† utiliser | `gpt-4o`, `gpt-4-turbo-preview`, `gpt-3.5-turbo` |
| `LLM_TEMPERATURE` | Cr√©ativit√© (0=d√©terministe, 1=cr√©atif) | `0.0` √† `1.0` |
| `VECTOR_STORE_TYPE` | Base vectorielle | `faiss` (recommand√©), `chroma` |
| `TOP_K_RESULTS` | Chunks r√©cup√©r√©s par recherche | `3` √† `10` (recommand√©: `5`) |
| `CHUNK_SIZE` | Taille des morceaux de texte | `500` √† `2000` (recommand√©: `1000`) |

---

## üéÆ Utilisation

### Lancer l'Application
```bash
# Depuis la racine du projet
streamlit run src/app.py
```

L'application s'ouvre automatiquement dans votre navigateur √† `http://localhost:8501`

### Workflow Typique

#### 1Ô∏è‚É£ **Uploader des Documents**

1. Aller dans **üìÑ Gestion des Documents**
2. Cliquer sur **"Parcourir"**
3. S√©lectionner un ou plusieurs fichiers (`.txt`, `.csv`, `.html`)
4. Cliquer sur **"üöÄ Traiter et Ajouter √† la Base"**
5. Attendre le traitement (barre de progression)
6. ‚úÖ Succ√®s : Les documents sont maintenant dans la base

#### 2Ô∏è‚É£ **Poser des Questions**

1. Aller dans **üí¨ Chat**
2. Taper une question dans le champ de saisie
3. Appuyer sur **Entr√©e**
4. La r√©ponse s'affiche avec les sources utilis√©es
5. Poser des questions de suivi (le contexte est pr√©serv√©)

#### 3Ô∏è‚É£ **G√©rer les Documents**

- **Voir les statistiques** : Nombre de chunks, documents, etc.
- **Supprimer un document** : Cliquer sur üóëÔ∏è √† c√¥t√© du document
- **Vider la base** : Utiliser le bouton "üóëÔ∏è Vider Compl√®tement la Base"

---

## üìÇ Structure du Projet
```
rag-legal-chatbot/
‚îÇ
‚îú‚îÄ‚îÄ README.md                    # Documentation principale
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances Python
‚îú‚îÄ‚îÄ .env                         # Configuration (√† cr√©er)
‚îú‚îÄ‚îÄ .env.example                 # Exemple de configuration
‚îú‚îÄ‚îÄ .gitignore                   # Fichiers ignor√©s par Git
‚îÇ
‚îú‚îÄ‚îÄ src/                         # Code source
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ app.py                   # Point d'entr√©e Streamlit
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/                  # Configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py          # Chargement variables .env
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                   # Utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_processor.py   # Traitement documents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py         # Gestion base vectorielle
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_handler.py          # Int√©gration LLM
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ components/              # Composants Streamlit
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ chat_interface.py       # Interface de chat
‚îÇ       ‚îî‚îÄ‚îÄ document_manager.py     # Gestion documents
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Donn√©es (cr√©√© automatiquement)
‚îÇ   ‚îú‚îÄ‚îÄ uploads/                 # Fichiers upload√©s
‚îÇ   ‚îî‚îÄ‚îÄ vector_store/            # Base vectorielle
‚îÇ       ‚îú‚îÄ‚îÄ faiss_index/         # Index FAISS
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ index.faiss
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ index.pkl
‚îÇ       ‚îî‚îÄ‚îÄ chroma_db/           # Base ChromaDB (si utilis√©)
‚îÇ
‚îî‚îÄ‚îÄ logs/                        # Logs (cr√©√© automatiquement)
    ‚îî‚îÄ‚îÄ app_2025-01-28.log       # Logs du jour
```

---

## üõ†Ô∏è Technologies

### Backend

| Technologie | Version | R√¥le |
|-------------|---------|------|
| **Python** | 3.11+ | Langage principal |
| **Streamlit** | 1.30+ | Framework web |
| **LangChain** | 0.1+ | Orchestration LLM et RAG |
| **OpenAI API** | 1.7+ | G√©n√©ration de r√©ponses (GPT-4) |
| **FAISS** | 1.7.4 | Base vectorielle (Facebook AI) |
| **BeautifulSoup** | 4.12+ | Parsing HTML |
| **Loguru** | 0.7+ | Logging avanc√© |

### Embeddings et Vector Stores

- **text-embedding-3-small** : Mod√®le d'embeddings OpenAI (1536 dimensions)
- **FAISS** : Recherche de similarit√© ultra-rapide (CPU)
- **ChromaDB** : Alternative (n√©cessite Build Tools sur Windows)

### Mod√®les LLM Support√©s

- ‚úÖ **gpt-4o** (recommand√©) - Dernier mod√®le, √©quilibr√©
- ‚úÖ **gpt-4-turbo-preview** - Haute qualit√©
- ‚úÖ **gpt-3.5-turbo** - √âconomique

---

## üêõ D√©pannage

### Probl√®me : `ModuleNotFoundError: No module named 'streamlit'`

**Solution** :
```bash
# V√©rifier que l'environnement virtuel est activ√©
.\venv\Scripts\Activate  # Windows
source venv/bin/activate  # macOS/Linux

# R√©installer les d√©pendances
pip install -r requirements.txt
```

---

### Probl√®me : `openai.error.AuthenticationError: Invalid API Key`

**Solution** :
1. V√©rifier que `.env` existe et contient `OPENAI_API_KEY=sk-proj-...`
2. V√©rifier que la cl√© est valide sur [OpenAI Platform](https://platform.openai.com/api-keys)
3. Red√©marrer l'application apr√®s modification du `.env`

---

### Probl√®me : `ImportError: DLL load failed while importing _faiss`

**Solution** (Windows) :
```bash
# D√©sinstaller et r√©installer FAISS
pip uninstall faiss-cpu
pip install faiss-cpu
```

Si le probl√®me persiste :
```bash
# Installer Microsoft Visual C++ Redistributable
# https://aka.ms/vs/17/release/vc_redist.x64.exe
```

---

### Probl√®me : `chromadb` ne s'installe pas sur Windows

**Solution** :
1. Installer [Microsoft Visual C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/)
2. OU utiliser FAISS √† la place :
```env
   VECTOR_STORE_TYPE=faiss
```

---

### Probl√®me : L'application est lente

**Solutions** :
1. R√©duire `TOP_K_RESULTS` dans `.env` (ex: `TOP_K_RESULTS=3`)
2. R√©duire `CHUNK_SIZE` (ex: `CHUNK_SIZE=500`)
3. Utiliser un mod√®le plus rapide (ex: `LLM_MODEL=gpt-3.5-turbo`)
4. V√©rifier que `@st.cache_resource` est bien utilis√© dans `app.py`

---

### Probl√®me : R√©ponses de mauvaise qualit√©

**Solutions** :
1. Augmenter `TOP_K_RESULTS` (ex: `TOP_K_RESULTS=7`)
2. Augmenter `CHUNK_OVERLAP` (ex: `CHUNK_OVERLAP=300`)
3. Utiliser un meilleur mod√®le (ex: `LLM_MODEL=gpt-4o`)
4. Am√©liorer la qualit√© des documents upload√©s

---

### Probl√®me : `PermissionError` lors de la suppression de fichiers

**Solution** (Windows) :
1. Fermer tous les programmes qui pourraient utiliser les fichiers
2. Red√©marrer l'application Streamlit
3. Si le probl√®me persiste, supprimer manuellement :
```powershell
   Remove-Item -Recurse -Force data/vector_store/*
```

---

## üìä Monitoring et Logs

### Voir les Logs en Temps R√©el
```bash
# Windows PowerShell
Get-Content -Path "logs/app_2025-01-28.log" -Wait

# macOS/Linux
tail -f logs/app_$(date +%Y-%m-%d).log
```

### Structure des Logs
```
2025-01-28 14:30:25 | INFO     | document_processor:process_file - üìÑ Traitement de contrat.txt
2025-01-28 14:30:26 | INFO     | vector_store:add_documents - ‚úÖ 15 chunks ajout√©s
2025-01-28 14:30:30 | INFO     | llm_handler:generate_response - üí¨ Question re√ßue: 'Quelle est...'
2025-01-28 14:30:32 | INFO     | llm_handler:generate_response - ‚úÖ R√©ponse g√©n√©r√©e (250 caract√®res)
```

### Niveaux de Log

- `DEBUG` : D√©tails techniques (seulement dans les fichiers)
- `INFO` : Op√©rations normales
- `WARNING` : Situations inhabituelles
- `ERROR` : Erreurs n√©cessitant attention

---

## üîí S√©curit√© et Confidentialit√©

### Bonnes Pratiques

1. ‚úÖ **Ne jamais committer `.env`** (d√©j√† dans `.gitignore`)
2. ‚úÖ **Ne pas partager votre cl√© API OpenAI**
3. ‚úÖ **Utiliser des cl√©s API avec quotas limit√©s** en production
4. ‚úÖ **V√©rifier que `data/` et `logs/` sont dans `.gitignore`**
5. ‚úÖ **Nettoyer r√©guli√®rement `data/uploads/`** (documents sensibles)

### Fichier `.gitignore` Recommand√©
```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
venv/
*.so

# Environnement
.env
.env.local

# Donn√©es sensibles
data/uploads/*
data/vector_store/*
!data/uploads/.gitkeep
!data/vector_store/.gitkeep

# Logs
logs/*.log

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db
```

---

## üöÄ Am√©liorations Futures

### Court Terme

- [ ] Support de formats additionnels (`.pdf`, `.docx`)
- [ ] Gestion de multiples bases vectorielles (par dossier juridique)
- [ ] Export de conversation en PDF
- [ ] Annotations et surlignage des sources

### Moyen Terme

- [ ] Authentification utilisateur (multi-utilisateurs)
- [ ] Historique persistant (base de donn√©es)
- [ ] API REST pour int√©gration
- [ ] Dashboard d'analytics (co√ªts, usage)

### Long Terme

- [ ] Fine-tuning d'un mod√®le sp√©cialis√© en droit fran√ßais
- [ ] OCR pour documents scann√©s
- [ ] Recherche hybride (keyword + s√©mantique)
- [ ] Int√©gration avec syst√®me de gestion documentaire



---

## üë• Auteurs

- **D√©veloppeur Principal** : Donald FEUZING NTEMMA
- **Client** : Cabinet d'avocats Emilia Parenti
- **Contact** : ntemmado@gmail.com

---

## üôè Remerciements

- [AI Siters](https://aisisters.ai/) pour ce test, une occasion d'apprendre. 
- [OpenAI](https://openai.com/) pour l'API GPT
- [LangChain](https://www.langchain.com/) pour le framework RAG
- [Streamlit](https://streamlit.io/) pour le framework web
- [Facebook AI Research](https://ai.facebook.com/) pour FAISS

**Fait avec ‚ù§Ô∏è pour le Cabinet Emilia Parenti**