"""
Gestion de la base vectorielle (FAISS ou ChromaDB)
"""
from pathlib import Path
from typing import List, Optional, Any
from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings
from loguru import logger

from src.config.settings import (
    VECTOR_STORE_DIR, 
    EMBEDDING_MODEL, 
    OPENAI_API_KEY,
    VECTOR_STORE_TYPE,
    TOP_K_RESULTS
)

# Import conditionnel selon configuration
if VECTOR_STORE_TYPE.lower() == "faiss":
    try:
        from langchain_community.vectorstores import FAISS as VectorStoreClass
    except ImportError:
        raise ImportError(
            "‚ùå FAISS n'est pas install√©.\n"
            "Installez-le avec: pip install faiss-cpu"
        )
elif VECTOR_STORE_TYPE.lower() == "chroma":
    try:
        from langchain_community.vectorstores import Chroma as VectorStoreClass
    except ImportError:
        raise ImportError(
            "‚ùå ChromaDB n'est pas install√©.\n"
            "Installez-le avec: pip install chromadb\n"
            "Note: N√©cessite Microsoft Visual C++ Build Tools sur Windows"
        )
else:
    raise ValueError(
        f"‚ùå VECTOR_STORE_TYPE '{VECTOR_STORE_TYPE}' non support√©.\n"
        f"Valeurs accept√©es: 'faiss', 'chroma'"
    )


class VectorStoreManager:
    """Gestionnaire de la base vectorielle (FAISS ou ChromaDB)"""
    
    def __init__(self):
        self.vector_store_type = VECTOR_STORE_TYPE.lower()
        
        # Chemin de stockage selon le type
        if self.vector_store_type == "faiss":
            self.vector_store_path = VECTOR_STORE_DIR / "faiss_index"
        else:  # chroma
            self.vector_store_path = VECTOR_STORE_DIR / "chroma_db"
        
        # Initialisation des embeddings
        self.embeddings = OpenAIEmbeddings(
            model=EMBEDDING_MODEL,
            openai_api_key=OPENAI_API_KEY
        )
        
        # Vector store (FAISS ou Chroma selon configuration)
        self.vector_store: Optional[Any] = None
        
        self._load_or_create()
        logger.info(f"‚úÖ VectorStoreManager initialis√© (type: {self.vector_store_type})")
    
    def _load_or_create(self):
        """Charge la base existante ou en cr√©e une nouvelle"""
        if self.vector_store_path.exists():
            try:
                if self.vector_store_type == "faiss":
                    from langchain_community.vectorstores import FAISS
                    self.vector_store = FAISS.load_local(
                        str(self.vector_store_path),
                        self.embeddings,
                        allow_dangerous_deserialization=True
                    )
                elif self.vector_store_type == "chroma":
                    from langchain_community.vectorstores import Chroma
                    self.vector_store = Chroma(
                        persist_directory=str(self.vector_store_path),
                        embedding_function=self.embeddings
                    )
                
                doc_count = self.get_document_count()
                logger.info(
                    f"‚úÖ Base vectorielle {self.vector_store_type.upper()} charg√©e "
                    f"depuis {self.vector_store_path} ({doc_count} chunks)"
                )
            except Exception as e:
                logger.warning(
                    f"‚ö†Ô∏è Impossible de charger la base existante: {e}. "
                    f"Cr√©ation d'une nouvelle base."
                )
                self.vector_store = None
        else:
            logger.info(
                f"üìù Aucune base {self.vector_store_type.upper()} existante. "
                f"Sera cr√©√©e au premier ajout."
            )
            self.vector_store = None
    
    def add_documents(self, documents: List[Document]) -> int:
        """
        Ajoute des documents √† la base vectorielle
        
        Args:
            documents: Liste de documents LangChain
            
        Returns:
            Nombre de documents ajout√©s
            
        Raises:
            Exception: Si erreur lors de l'ajout
        """
        if not documents:
            logger.warning("‚ö†Ô∏è Aucun document √† ajouter")
            return 0
        
        try:
            if self.vector_store is None:
                # Cr√©er la base pour la premi√®re fois
                logger.info(
                    f"üî® Cr√©ation de la base {self.vector_store_type.upper()} "
                    f"avec {len(documents)} documents..."
                )
                
                if self.vector_store_type == "faiss":
                    from langchain_community.vectorstores import FAISS
                    self.vector_store = FAISS.from_documents(documents, self.embeddings)
                elif self.vector_store_type == "chroma":
                    from langchain_community.vectorstores import Chroma
                    self.vector_store = Chroma.from_documents(
                        documents=documents,
                        embedding=self.embeddings,
                        persist_directory=str(self.vector_store_path)
                    )
                
                logger.info(f"‚úÖ Nouvelle base cr√©√©e avec {len(documents)} chunks")
            else:
                # Ajouter √† la base existante
                logger.info(f"‚ûï Ajout de {len(documents)} documents √† la base existante...")
                self.vector_store.add_documents(documents)
                logger.info(
                    f"‚úÖ {len(documents)} chunks ajout√©s "
                    f"(total: {self.get_document_count()})"
                )
            
            # Sauvegarder automatiquement
            self.save()
            return len(documents)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'ajout de documents: {e}")
            raise
    
    def similarity_search(self, query: str, k: int = None) -> List[Document]:
        """
        Recherche les documents les plus similaires √† une requ√™te
        
        Args:
            query: Question de l'utilisateur
            k: Nombre de r√©sultats (par d√©faut: TOP_K_RESULTS depuis .env)
            
        Returns:
            Liste de documents pertinents (tri√©s par similarit√© d√©croissante)
        """
        if self.vector_store is None:
            logger.warning("‚ö†Ô∏è Base vectorielle vide, aucune recherche possible")
            return []
        
        if not query or query.strip() == "":
            logger.warning("‚ö†Ô∏è Requ√™te vide")
            return []
        
        # Utiliser TOP_K_RESULTS si k non sp√©cifi√©
        if k is None:
            k = TOP_K_RESULTS
        
        try:
            logger.info(f"üîç Recherche de similarit√© pour: '{query[:50]}...' (k={k})")
            results = self.vector_store.similarity_search(query, k=k)
            logger.info(f"‚úÖ {len(results)} r√©sultats trouv√©s")
            
            # Log des sources trouv√©es
            if results:
                sources = set(doc.metadata.get("source", "Unknown") for doc in results)
                logger.debug(f"üìö Sources: {', '.join(sources)}")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la recherche: {e}")
            return []
    
    def similarity_search_with_score(
        self, 
        query: str, 
        k: int = None
    ) -> List[tuple[Document, float]]:
        """
        Recherche avec scores de similarit√©
        
        Args:
            query: Question de l'utilisateur
            k: Nombre de r√©sultats (par d√©faut: TOP_K_RESULTS)
            
        Returns:
            Liste de tuples (Document, score)
        """
        if self.vector_store is None:
            logger.warning("‚ö†Ô∏è Base vectorielle vide")
            return []
        
        # Utiliser TOP_K_RESULTS si k non sp√©cifi√©
        if k is None:
            k = TOP_K_RESULTS
        
        try:
            results = self.vector_store.similarity_search_with_score(query, k=k)
            logger.info(f"‚úÖ {len(results)} r√©sultats avec scores trouv√©s")
            return results
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la recherche avec score: {e}")
            return []
    
    def delete_by_source(self, source_name: str) -> bool:
        """
        Supprime tous les documents d'une source donn√©e
        
        Note: FAISS ne supporte pas la suppression native,
        donc on doit reconstruire la base sans les documents √† supprimer
        
        Args:
            source_name: Nom du fichier source (ex: "contrat.txt")
            
        Returns:
            True si succ√®s, False sinon
        """
        if self.vector_store is None:
            logger.warning("‚ö†Ô∏è Base vectorielle vide, rien √† supprimer")
            return False
        
        try:
            logger.info(f"üóëÔ∏è Suppression des documents de la source: {source_name}")
            
            if self.vector_store_type == "chroma":
                # ChromaDB supporte la suppression native
                # R√©cup√©rer les IDs des documents √† supprimer
                all_data = self.vector_store.get()
                ids_to_delete = [
                    doc_id 
                    for doc_id, metadata in zip(all_data['ids'], all_data['metadatas'])
                    if metadata.get('source') == source_name
                ]
                
                if ids_to_delete:
                    self.vector_store.delete(ids_to_delete)
                    logger.info(f"‚úÖ {len(ids_to_delete)} chunks supprim√©s")
                    return True
                else:
                    logger.warning(f"‚ö†Ô∏è Aucun document trouv√© avec la source: {source_name}")
                    return False
            
            else:  # FAISS
                # FAISS: reconstruire la base
                all_docs = self._get_all_documents()
                
                if not all_docs:
                    logger.warning("‚ö†Ô∏è Aucun document dans la base")
                    return False
                
                # Filtrer : garder tous SAUF ceux de la source √† supprimer
                filtered_docs = [
                    doc for doc in all_docs 
                    if doc.metadata.get("source") != source_name
                ]
                
                deleted_count = len(all_docs) - len(filtered_docs)
                if deleted_count == 0:
                    logger.warning(f"‚ö†Ô∏è Aucun document trouv√© avec la source: {source_name}")
                    return False
                
                # Reconstruire la base
                if filtered_docs:
                    logger.info(f"üî® Reconstruction de la base avec {len(filtered_docs)} chunks...")
                    from langchain_community.vectorstores import FAISS
                    self.vector_store = FAISS.from_documents(filtered_docs, self.embeddings)
                    logger.info(
                        f"‚úÖ {deleted_count} chunks supprim√©s. "
                        f"{len(filtered_docs)} chunks restants."
                    )
                else:
                    logger.info("üìù Plus aucun document, base vid√©e")
                    self.vector_store = None
                
                self.save()
                return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la suppression: {e}")
            return False
    
    def _get_all_documents(self) -> List[Document]:
        """
        R√©cup√®re tous les documents de la base
        
        Utilis√© pour la suppression (car FAISS ne permet pas la suppression directe)
        
        Returns:
            Liste de tous les documents
        """
        if self.vector_store is None:
            return []
        
        try:
            if self.vector_store_type == "faiss":
                # Acc√©der au docstore interne de FAISS
                docstore = self.vector_store.docstore
                all_docs = []
                
                # Parcourir tous les documents via index_to_docstore_id
                for doc_id in self.vector_store.index_to_docstore_id.values():
                    doc = docstore.search(doc_id)
                    if doc:
                        all_docs.append(doc)
                
                logger.debug(f"üìã {len(all_docs)} documents r√©cup√©r√©s depuis FAISS")
                return all_docs
            
            elif self.vector_store_type == "chroma":
                # ChromaDB a une m√©thode get() directe
                results = self.vector_store.get()
                all_docs = []
                
                for doc_id, text, metadata in zip(
                    results['ids'], 
                    results['documents'], 
                    results['metadatas']
                ):
                    doc = Document(page_content=text, metadata=metadata)
                    all_docs.append(doc)
                
                logger.debug(f"üìã {len(all_docs)} documents r√©cup√©r√©s depuis ChromaDB")
                return all_docs
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des documents: {e}")
            return []
    
    def get_document_count(self) -> int:
        """
        Retourne le nombre total de chunks dans la base
        
        Returns:
            Nombre de chunks (0 si base vide)
        """
        if self.vector_store is None:
            return 0
        
        try:
            if self.vector_store_type == "faiss":
                # FAISS stocke le nombre de vecteurs dans index.ntotal
                count = self.vector_store.index.ntotal
            elif self.vector_store_type == "chroma":
                # ChromaDB utilise la m√©thode count()
                count = self.vector_store._collection.count()
            
            return count
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du comptage: {e}")
            return 0
    
    def get_all_sources(self) -> List[str]:
        """
        Retourne la liste de toutes les sources (noms de fichiers) dans la base
        
        Returns:
            Liste tri√©e des noms de fichiers sources
        """
        if self.vector_store is None:
            return []
        
        try:
            all_docs = self._get_all_documents()
            
            # Extraire les sources uniques
            sources = set()
            for doc in all_docs:
                source = doc.metadata.get("source", "Unknown")
                sources.add(source)
            
            sorted_sources = sorted(list(sources))
            logger.debug(f"üìö Sources trouv√©es: {sorted_sources}")
            return sorted_sources
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des sources: {e}")
            return []
    
    def save(self):
        """
        Sauvegarde la base vectorielle sur disque
        
        FAISS cr√©e les fichiers :
        - index.faiss : Index vectoriel
        - index.pkl : M√©tadonn√©es et docstore
        
        ChromaDB sauvegarde automatiquement dans persist_directory
        """
        if self.vector_store is None:
            logger.debug("üìù Aucune base √† sauvegarder (base vide)")
            return
        
        try:
            # Cr√©er le dossier si n√©cessaire
            self.vector_store_path.parent.mkdir(parents=True, exist_ok=True)
            
            if self.vector_store_type == "faiss":
                self.vector_store.save_local(str(self.vector_store_path))
            elif self.vector_store_type == "chroma":
                # ChromaDB sauvegarde automatiquement avec persist_directory
                self.vector_store.persist()
            
            logger.info(
                f"üíæ Base {self.vector_store_type.upper()} sauvegard√©e "
                f"dans {self.vector_store_path}"
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la sauvegarde: {e}")
            raise
    
    def clear(self):
        """
        Efface compl√®tement la base vectorielle (m√©moire + disque)
        """
        try:
            # Effacer de la m√©moire
            self.vector_store = None
            
            # Supprimer les fichiers sur disque
            if self.vector_store_path.exists():
                import shutil
                shutil.rmtree(self.vector_store_path)
                logger.info(
                    f"üóëÔ∏è Base {self.vector_store_type.upper()} effac√©e "
                    f"(m√©moire + disque)"
                )
            else:
                logger.info(
                    f"üóëÔ∏è Base {self.vector_store_type.upper()} effac√©e "
                    f"(m√©moire uniquement)"
                )
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'effacement: {e}")
            raise
    
    def get_stats(self) -> dict:
        """
        Retourne des statistiques sur la base vectorielle
        
        Returns:
            Dictionnaire avec statistiques
        """
        if self.vector_store is None:
            return {
                "total_chunks": 0,
                "total_sources": 0,
                "sources": [],
                "status": "empty",
                "vector_store_type": self.vector_store_type,
                "embedding_model": EMBEDDING_MODEL,
                "top_k_results": TOP_K_RESULTS
            }
        
        try:
            sources = self.get_all_sources()
            return {
                "total_chunks": self.get_document_count(),
                "total_sources": len(sources),
                "sources": sources,
                "status": "ready",
                "vector_store_type": self.vector_store_type,
                "embedding_model": EMBEDDING_MODEL,
                "top_k_results": TOP_K_RESULTS
            }
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des stats: {e}")
            return {
                "total_chunks": 0,
                "total_sources": 0,
                "sources": [],
                "status": "error",
                "vector_store_type": self.vector_store_type,
                "embedding_model": EMBEDDING_MODEL,
                "top_k_results": TOP_K_RESULTS
            }